{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75294, "ImageNetV2:top1": 0.6371}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 1e-06, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75512, "ImageNetV2:top1": 0.6414}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 1e-05, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75424, "ImageNetV2:top1": 0.6387}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0001, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75486, "ImageNetV2:top1": 0.6428}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.001, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75408, "ImageNetV2:top1": 0.6377}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.01, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.75496, "ImageNetV2:top1": 0.6425}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.1, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.704, "ImageNetV2:top1": 0.6064}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 1.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.0, "ImageNet:top1": 0.38122, "ImageNetV2:top1": 0.3236}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0, "wd": 0.01, "ImageNet:top1": 0.62802, "ImageNetV2:top1": 0.5521}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 1e-05, "wd": 0.01, "ImageNet:top1": 0.73862, "ImageNetV2:top1": 0.6317}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.0001, "wd": 0.01, "ImageNet:top1": 0.75464, "ImageNetV2:top1": 0.6416}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 10, "lr": 0.001, "wd": 0.01, "ImageNet:top1": 0.73638, "ImageNetV2:top1": 0.6099}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 5, "lr": 0.0, "wd": 0.01, "ImageNet:top1": 0.63024, "ImageNetV2:top1": 0.5547}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 5, "lr": 1e-05, "wd": 0.01, "ImageNet:top1": 0.72802, "ImageNetV2:top1": 0.6261}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 5, "lr": 0.0001, "wd": 0.01, "ImageNet:top1": 0.75376, "ImageNetV2:top1": 0.6406}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 5, "lr": 0.001, "wd": 0.01, "ImageNet:top1": 0.74066, "ImageNetV2:top1": 0.6176}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 2, "lr": 0.0, "wd": 0.01, "ImageNet:top1": 0.6293, "ImageNetV2:top1": 0.5531}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 2, "lr": 1e-05, "wd": 0.01, "ImageNet:top1": 0.70958, "ImageNetV2:top1": 0.6118}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 2, "lr": 0.0001, "wd": 0.01, "ImageNet:top1": 0.74634, "ImageNetV2:top1": 0.6363}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 2, "lr": 0.001, "wd": 0.01, "ImageNet:top1": 0.74596, "ImageNetV2:top1": 0.6256}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 1, "lr": 0.0, "wd": 0.01, "ImageNet:top1": 0.62996, "ImageNetV2:top1": 0.5542}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 1, "lr": 1e-05, "wd": 0.01, "ImageNet:top1": 0.69412, "ImageNetV2:top1": 0.603}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 1, "lr": 0.0001, "wd": 0.01, "ImageNet:top1": 0.73768, "ImageNetV2:top1": 0.631}
{"template_name": "none", "dropout_prompts": -1, "skip_renorm": false, "method": "pytorch_warmstart_probe", "model_name": "CLIP Logistic Regression", "subtype": "ViT-B/32", "batch_size": 128, "train_dataset": "ImageNet", "alpha": 0.0, "beta": -1, "lam": 0.316, "iters": 1000, "cvar_quantile": 0, "penalty": "l2", "rho": "none", "solver": "lbfgs", "epochs": 1, "lr": 0.001, "wd": 0.01, "ImageNet:top1": 0.74202, "ImageNetV2:top1": 0.6284}
